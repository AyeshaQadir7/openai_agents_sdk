{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## <font color= orange>**Global, Run & Agent Level Config**</font>"
      ],
      "metadata": {
        "id": "dkrRPCsV0Yci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Agents SDK version (as of 0.2.9, released August 22, 2025) hasn't yet been updated to support the openai SDK changes that removed ResponseTextConfigParam. This mismatch causes the ImportError**\n",
        "\n",
        "**Debug information**\n",
        "* Agents SDK version: 0.2.8\n",
        "* Python version: 3.12.2\n",
        "\n",
        "```!pip install openai==0.28.0 ```"
      ],
      "metadata": {
        "id": "KOdMMVot-d0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28.0\n"
      ],
      "metadata": {
        "id": "iuI6iKyl06B5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "2cd79699-aab0-4019-b84d-b3a4a7cde060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28.0\n",
            "  Using cached openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.12/dist-packages (from openai==0.28.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai==0.28.0) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from openai==0.28.0) (3.12.15)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28.0) (2025.8.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28.0) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28.0) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->openai==0.28.0) (4.14.1)\n",
            "Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.101.0\n",
            "    Uninstalling openai-1.101.0:\n",
            "      Successfully uninstalled openai-1.101.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "openai-agents 0.2.9 requires openai<2,>=1.99.6, but you have openai 0.28.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq openai-agents"
      ],
      "metadata": {
        "id": "cPouSUi7-MoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "0dASQT5A0974"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")"
      ],
      "metadata": {
        "id": "JqQ-oKINB0Ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Global Config**\n",
        "\n",
        "* Applies to the **entire SDK session or application**.\n",
        "* Think of it as ‚Äúdefault environment settings‚Äù for everything.\n",
        "* Example: API keys, default LLM provider, logging, safety filters.\n",
        "\n",
        "üí° Analogy: **School rules** ‚Üí apply to all students unless a teacher overrides them."
      ],
      "metadata": {
        "id": "ozojZA0J0bPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import (\n",
        "    Agent,\n",
        "    Runner,\n",
        "    AsyncOpenAI,\n",
        "    OpenAIChatCompletionsModel,\n",
        "    RunConfig,\n",
        "    set_default_openai_client,\n",
        "    set_default_openai_api,\n",
        "    set_tracing_disabled\n",
        ")\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Global Configurations (apply to ALL agents/runs unless overridden)\n",
        "\n",
        "set_default_openai_api(\"chat_completions\")   # Global default: use chat-completions API\n",
        "set_tracing_disabled(True)                   # Global default: disable tracing/logging everywhere\n",
        "\n",
        "# API Key setup\n",
        "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = GEMINI_API_KEY   # Optional, for compatibility with OpenAI clients\n",
        "\n",
        "MODEL_NAME = \"gemini-2.5-flash\"\n",
        "\n",
        "# Global client (all agents/runs use this unless overridden)\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=GEMINI_API_KEY,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "set_default_openai_client(external_client)   # ‚úÖ Global client override\n",
        "\n",
        "\n",
        "\n",
        "# Agent-Level Configuration (specific agent instructions + model)\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=MODEL_NAME,\n",
        "    openai_client=external_client,   # agent uses the Gemini-backed client\n",
        ")\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=\"You are a helpful assistant\",  # agent persona\n",
        "    model=model,                                 # agent‚Äôs default model\n",
        ")\n",
        "\n",
        "# Run-Level Configuration (optional overrides for this run)\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,                 # Run-specific model (can override global/agent)\n",
        "    model_provider=external_client,\n",
        "    tracing_disabled=True,       # Run-specific tracing config (overrides global if needed)\n",
        ")\n",
        "\n",
        "# Execute the run with agent + input\n",
        "result = Runner.run_sync(\n",
        "    starting_agent=agent,\n",
        "    input=\"Hello\",\n",
        "    run_config=config            # explicitly pass run config (best practice)\n",
        ")\n",
        "\n",
        "print(result.final_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnYT33Wc0deB",
        "outputId": "8dd6bbf5-2c2e-4ae1-f91d-9318490de49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello there! How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Agent Config**\n",
        "\n",
        "* Applies to a **specific agent instance**.\n",
        "* Defines the agent‚Äôs **role, tools, memory, and default model**.\n",
        "* Example: FinanceAgent always uses `gpt-4` + stock API; TravelAgent uses `gpt-4-mini` + booking API.\n",
        "\n",
        "üí° Analogy: **Each teacher‚Äôs teaching style** ‚Üí math teacher vs history teacher."
      ],
      "metadata": {
        "id": "DaeUHcPnBUA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from openai import AsyncOpenAI\n",
        "from agents import Agent, OpenAIChatCompletionsModel, Runner\n",
        "\n",
        "# Client Setup (Gemini provider via OpenAI-compatible API)\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=GEMINI_API_KEY,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Agent-Level Configuration\n",
        "# Here, the MODEL is bound directly to the agent itself.\n",
        "# This means: whenever this agent is used, it will always call Gemini 2.5 Flash,\n",
        "# regardless of any run config (unless overridden explicitly at run time).\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Assistant\",\n",
        "        instructions=\"You only respond in Urdu.\",   # Agent persona\n",
        "        model=OpenAIChatCompletionsModel(\n",
        "            model=\"gemini-2.5-flash\",               # Specific model for THIS agent\n",
        "            openai_client=client,                   # Custom provider (Gemini API)\n",
        "        ),\n",
        "    )\n",
        "\n",
        "\n",
        "    # Run Execution\n",
        "\n",
        "    result = await Runner.run(\n",
        "        agent,\n",
        "        \"I am learning Agentic AI with Panaversity Community\",\n",
        "    )\n",
        "\n",
        "    # Output will be in Urdu because of the agent's instructions\n",
        "    print(result.final_output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCPDjBU2CvNI",
        "outputId": "5e52806b-9034-45a3-b15a-d8bbb51227b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÿ®€Åÿ™ ÿÆŸàÿ®! Ÿæ€åŸÜÿßŸàÿ±ÿ≥Ÿπ€å ⁄©ŸÖ€åŸàŸÜŸπ€å ⁄©€í ÿ≥ÿßÿ™⁄æ ÿß€åÿ¨ŸÜŸπ⁄© ÿß€í ÿ¢ÿ¶€å ÿ≥€å⁄©⁄æŸÜÿß ÿß€å⁄© ÿ®€Åÿ™ÿ±€åŸÜ ŸÇÿØŸÖ €Å€í€î\n",
            "\n",
            "ÿ¢Ÿæ ⁄©€å ÿ≥€å⁄©⁄æŸÜ€í ⁄©€å €å€Å ⁄©Ÿàÿ¥ÿ¥ ÿ®€Åÿ™ ⁄©ÿßŸÖ€åÿßÿ® €ÅŸà€î\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Run Config**\n",
        "\n",
        "* Applies to **a single agent run (conversation or task execution)**.\n",
        "* Lets you override some global defaults for that run.\n",
        "* Example: Change model or temperature **just for one run** without affecting others.\n",
        "\n",
        "üí° Analogy: **Class session rules** ‚Üí teacher says ‚Äútoday we do group work‚Äù even though school normally does lectures.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sqYcYX0RE3eg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel\n",
        "from agents.run import RunConfig\n",
        "\n",
        "\n",
        "# LLM Client Setup (acts like a global but scoped manually here)\n",
        "\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=GEMINI_API_KEY,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "\n",
        "# Model Configuration (used by this agent/run)\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=external_client,   # tells the model to use Gemini instead of OpenAI\n",
        ")\n",
        "\n",
        "\n",
        "# Agent-Level Configuration\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=\"You are a helpful assistant\"\n",
        ")\n",
        "\n",
        "# Run-Level Configuration\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,                     # run will use this Gemini model\n",
        "    model_provider=external_client,  # Gemini client for this run\n",
        "    tracing_disabled=True            # disable tracing for this run\n",
        ")\n",
        "\n",
        "# Run Execution\n",
        "\n",
        "result = Runner.run_sync(\n",
        "    starting_agent=agent,\n",
        "    input=\"Hello, how are you?\",\n",
        "    run_config=config                # RunConfig overrides what the agent uses\n",
        ")\n",
        "\n",
        "print(result.final_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olDKmBn9Bk1D",
        "outputId": "1e1cc4d7-bd6b-431b-b561-4b5ecc78874f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am doing well, thank you for asking! How are you today?\n",
            "\n"
          ]
        }
      ]
    }
  ]
}