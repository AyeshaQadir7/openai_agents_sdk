{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Agent Tools & Handoffs**"
      ],
      "metadata": {
        "id": "uMG0Hftg_q8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What are Tools in Agents?**\n",
        "\n",
        "In Agentic AI:\n",
        "\n",
        "* **LLMs can‚Äôt actually ‚Äúdo‚Äù things** on their own (like fetch real data, run code, or call APIs).\n",
        "* **Tools** are how you let an agent *extend its powers* by calling **functions you define in Python** (or external APIs).\n",
        "* The agent decides *when* and *how* to call a tool, based on the user‚Äôs input.\n",
        "\n",
        "Think of tools as:\n",
        "üëâ *‚Äúskills or superpowers that an agent can use when it can‚Äôt just rely on text reasoning.‚Äù*\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "# **How Tools Work in the Agent Loop**\n",
        "\n",
        "1. **User gives input** ‚Üí ‚ÄúWhat‚Äôs the weather in Karachi?‚Äù\n",
        "2. Agent tries to solve it.\n",
        "3. If the model realizes it needs external info, it says:\n",
        "\n",
        "   > *‚ÄúI should call the `get_weather` tool with city=Karachi.‚Äù*\n",
        "4. The SDK executes your Python function (`get_weather(\"Karachi\")`).\n",
        "5. The tool‚Äôs output is fed back to the agent.\n",
        "6. The agent produces the **final answer** to the user.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "# **Defining Tools**\n",
        "\n",
        "The SDK makes this **super simple**. You use the `@function_tool` decorator.\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "from agents import function_tool\n",
        "\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Fetches weather for a given city.\"\"\"\n",
        "    return f\"The weather in {city} is sunny with 30¬∞C.\"\n",
        "```\n",
        "\n",
        "* The decorator does the heavy lifting:\n",
        "\n",
        "  * It tells the agent **what the function does** (docstring).\n",
        "  * It registers the function signature (`city: str`).\n",
        "  * It makes the tool available for the agent‚Äôs reasoning loop.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "# **Adding Tools to an Agent**\n",
        "\n",
        "When you create the agent, just pass a list of tools:\n",
        "\n",
        "```python\n",
        "from agents import Agent\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"WeatherBot\",\n",
        "    instructions=\"You answer weather-related questions.\",\n",
        "    tools=[get_weather],   # ‚úÖ now agent can call this tool\n",
        ")\n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "# **Why Tools are Powerful**\n",
        "\n",
        "* **APIs** ‚Üí connect to weather, stock prices, databases.\n",
        "* **Math/logic** ‚Üí do calculations the LLM can‚Äôt.\n",
        "* **Custom workflows** ‚Üí trigger emails, run SQL queries, call other services.\n",
        "* **Multi-agent collaboration** ‚Üí one agent can call another as a ‚Äútool.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ **In short:**\n",
        "Tools let you go *beyond text*.\n",
        "They turn an LLM from a *talker* ‚Üí into a *doer*.\n",
        "\n"
      ],
      "metadata": {
        "id": "PWzvQ46BgxjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-agents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ulYpwLCnZUBX",
        "outputId": "5fa3ecf6-917b-4c29-9e19-0d3557aafd5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-agents\n",
            "  Downloading openai_agents-0.2.9-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting griffe<2,>=1.5.6 (from openai-agents)\n",
            "  Downloading griffe-1.13.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: mcp<2,>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (1.13.1)\n",
            "Requirement already satisfied: openai<2,>=1.99.6 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (1.101.0)\n",
            "Requirement already satisfied: pydantic<3,>=2.10 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (2.32.4)\n",
            "Collecting types-requests<3,>=2.0 (from openai-agents)\n",
            "  Downloading types_requests-2.32.4.20250809-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (4.15.0)\n",
            "Collecting colorama>=0.4 (from griffe<2,>=1.5.6->openai-agents)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (4.10.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.4.1)\n",
            "Requirement already satisfied: httpx>=0.27.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.28.1)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (4.25.1)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (2.10.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (3.0.2)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.47.3)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.35.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.99.6->openai-agents) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.99.6->openai-agents) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.99.6->openai-agents) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.99.6->openai-agents) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.10->openai-agents) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.27.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp<2,>=1.11.0->openai-agents) (1.1.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.31.1->mcp<2,>=1.11.0->openai-agents) (8.2.1)\n",
            "Downloading openai_agents-0.2.9-py3-none-any.whl (175 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading griffe-1.13.0-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250809-py3-none-any.whl (20 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: types-requests, colorama, griffe, openai-agents\n",
            "Successfully installed colorama-0.4.6 griffe-1.13.0 openai-agents-0.2.9 types-requests-2.32.4.20250809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "o40kr-Z3ydGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import os\n",
        "\n",
        "from agents import  Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel, function_tool, set_tracing_disabled\n",
        "from google.colab import userdata\n",
        "\n",
        "# Debug Logging\n",
        "# from agents import enable_verbose_stdout_logging,\n",
        "# enable_verbose_stdout_logging()\n",
        "\n",
        "# Disable tracing globally\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "# Setup key\n",
        "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "MODEL= \"gemini-2.5-flash\"\n",
        "\n",
        "external_client= AsyncOpenAI(\n",
        "    api_key= GEMINI_API_KEY,\n",
        "    base_url= \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model= OpenAIChatCompletionsModel(\n",
        "    model= MODEL,\n",
        "    openai_client= external_client,\n",
        ")\n",
        "\n",
        "# Example tool\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "  print(\"[DEBUG] getting the weather data\")\n",
        "  return f\"The weather in {city} is sunny.\"\n",
        "\n",
        "# Agent\n",
        "agent = Agent(\n",
        "    name= \"Assistant\",\n",
        "    instructions= \"You only respond in haikus.\",\n",
        "    model= model,\n",
        "    tools= [get_weather],\n",
        ")\n",
        "\n",
        "async def main():\n",
        "  result = await Runner.run(starting_agent= agent, input=\"What is current weather in Karachi.\")\n",
        "  print(result.final_output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2DIYPpdZZRX",
        "outputId": "1a752c42-02c0-41f5-e9e7-497f05548fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] getting the weather data\n",
            "Sun shines bright today,\n",
            "In Karachi's warm embrace,\n",
            "Clear skies, no clouds roam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What is a Handoff?**\n",
        "\n",
        "A **handoff** happens when one agent decides it **can‚Äôt (or shouldn‚Äôt) finish the task itself** and instead passes control to another agent.\n",
        "\n",
        "Think of it like a customer support team:\n",
        "\n",
        "* The **triage agent** (front desk) takes your request.\n",
        "* If it‚Äôs a billing issue, it **hands off** to the billing agent.\n",
        "* If it‚Äôs technical, it **hands off** to the tech agent.\n",
        "\n",
        "üëâ In agent systems, a **handoff = structured baton pass** between agents.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "# **How It Works in the Agent Loop**\n",
        "\n",
        "1. **Agent A receives input**\n",
        "   ‚Üí Example: ‚ÄúSummarize this PDF.‚Äù\n",
        "\n",
        "2. **Agent A realizes**:\n",
        "\n",
        "   > ‚ÄúI don‚Äôt handle documents. I should hand this off to `DocumentAgent`.‚Äù\n",
        "\n",
        "3. **Handoff step is emitted** by Agent A.\n",
        "\n",
        "   * The SDK pauses execution.\n",
        "   * The baton is passed to the target agent.\n",
        "\n",
        "4. **Agent B takes over** with the same context/input.\n",
        "\n",
        "   * Processes the task.\n",
        "   * Produces its own output.\n",
        "\n",
        "5. **Control returns to the loop** (depending on configuration).\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "# **Why Handoff is Useful**\n",
        "\n",
        "* **Multi-Agent Specialization**: Agents can each be good at one thing (math, research, coding, support).\n",
        "* **Cleaner logic**: Instead of cramming one giant agent with all tools, you route to the right expert.\n",
        "* **Triage agents** use handoff heavily ‚Üí they *decide where to send the request*.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "# **Difference Between Tool Calls and Handoffs**\n",
        "\n",
        "* **Tool** = agent says: *‚ÄúLet me call this helper function and use its result.‚Äù*\n",
        "* **Handoff** = agent says: *‚ÄúI can‚Äôt do this; another whole agent should take over.‚Äù*\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "‚úÖ **In short:**\n",
        "Handoff is how agents **pass control to another agent** in the loop.\n",
        "It‚Äôs the backbone of **multi-agent systems** where each agent is a specialist.\n",
        "\n"
      ],
      "metadata": {
        "id": "gAjNUat5hSW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq openai-agents  \"openai-agents[litellm]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYAlBtR6aBHf",
        "outputId": "ffd57b3e-ebd0-4d85-841d-736d99520974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "x3bJTxt2aOCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "from agents import Agent, Runner, set_tracing_disabled, function_tool\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "from google.colab import userdata\n",
        "\n",
        "set_tracing_disabled(disabled= True)\n",
        "\n",
        "MODEL= \"gemini/gemini-2.5-flash\"\n",
        "GEMINI_API_KEY= userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "  return f\"The weather in {city} is sunny.\"\n",
        "\n",
        "weather_agent = Agent(\n",
        "    name='WeatherAssistant',\n",
        "    instructions= \"You will answer weather relevent questions\",\n",
        "    model= LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "    tools= [get_weather],\n",
        "    handoff_description= \"Weather Assistant is a specialized for all weather queries.\",\n",
        ")\n",
        "\n",
        "panaversity_agent= Agent(\n",
        "    name= \"PanaversityAssistant\",\n",
        "    instructions= \"You will answer Panaversity related queries\",\n",
        "    model= LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "    handoff_description=\"Panaversity Assistant is a specializes for all panaversity releated queries. Panaversity is an educational program.\"\n",
        ")\n",
        "\n",
        "triage_agent = Agent(\n",
        "    name= \"GeneralAssistant\",\n",
        "    instructions= \"You will chat with user for general questions and handoff to Specialized agent\",\n",
        "    model= LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "    handoffs= [weather_agent, panaversity_agent],\n",
        "    tools= [get_weather]\n",
        ")\n",
        "\n",
        "result = Runner.run_sync(triage_agent, \"Hello\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VT6bpIfaJOH",
        "outputId": "269f2bfa-e96a-450b-d2d3-6da9a9d373f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I help you today?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oFS2XyJEUDI3",
        "outputId": "f0f72ae7-997c-4cb6-d6f0-8bcfa090b9be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__dataclass_fields__',\n",
              " '__dataclass_params__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__match_args__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_last_agent',\n",
              " 'context_wrapper',\n",
              " 'final_output',\n",
              " 'final_output_as',\n",
              " 'input',\n",
              " 'input_guardrail_results',\n",
              " 'last_agent',\n",
              " 'last_response_id',\n",
              " 'new_items',\n",
              " 'output_guardrail_results',\n",
              " 'raw_responses',\n",
              " 'to_input_list']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.last_agent.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wbaT9hqtYJ_2",
        "outputId": "2f639763-799a-4d8e-c3d6-c93db39dbddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GeneralAssistant'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result= Runner.run_sync(triage_agent, \"What is the weather in karachi\")\n",
        "print(result.final_output)\n",
        "print(result.last_agent.name)\n",
        "\n",
        "print(\"-\" * 10)\n",
        "\n",
        "result= Runner.run_sync(triage_agent, \"What is panaversity\")\n",
        "print(result.final_output)\n",
        "print(result.last_agent.name)\n",
        "\n",
        "print(\"-\" * 10)\n",
        "\n",
        "result= Runner.run_sync(triage_agent, \"Hi There!\")\n",
        "print(result.final_output)\n",
        "print(result.last_agent.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrneigTEf-wo",
        "outputId": "cb37944a-be98-43bf-899d-129dc9d74fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] getting the weather data\n",
            "The weather in Karachi is sunny.\n",
            "WeatherAssistant\n",
            "----------\n",
            "Panaversity is an innovative educational platform designed to offer a comprehensive and universal learning experience. It combines the concept of a \"university\" (indicating a focus on higher learning and knowledge acquisition) with the prefix \"Pana-\" (meaning \"all,\" \"every,\" or \"worldwide\").\n",
            "\n",
            "Therefore, Panaversity represents a broad-reaching educational initiative, potentially offering diverse courses, programs, and resources accessible to a global audience, aiming to provide holistic and inclusive learning opportunities across various fields of study.\n",
            "PanaversityAssistant\n",
            "----------\n",
            "Hello! How can I help you today?\n",
            "\n",
            "GeneralAssistant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result= Runner.run_sync(triage_agent, \"what is panaversity and also what is the weather of kaarchi today?\")\n",
        "print(result.final_output)\n",
        "print(result.last_agent.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOoZUViPiV4p",
        "outputId": "d0fae39c-7f4f-4522-c1c4-5812164e4a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weather in Karachi is sunny.\n",
            "\n",
            "Panaversity is an educational program. Would you like to know more about it?\n",
            "GeneralAssistant\n"
          ]
        }
      ]
    }
  ]
}