{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **What Are Hosted Tools?**\n",
        "[Colab notebook link][1]\n",
        "\n",
        "[1]: https://colab.research.google.com/drive/1b6QDK6iVwHwmQBlZGeEXdiyVYxg7m3kb?usp=sharing\n",
        "\n",
        "**Hosted tools** are prebuilt, managed capabilities that run **on OpenAI's servers alongside language models**. They free you from writing your own API integrations or hosting infrastructure.\n",
        "\n",
        "They‚Äôre different from:\n",
        "\n",
        "* **Function tools** (your own Python functions wrapped as callable tools).\n",
        "* **Agents-as-tools** (where an entire agent is callable within another).\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "## **Examples of Hosted Tools in the Agents SDK**\n",
        "\n",
        "OpenAI includes several built-in tools you can drop into any agent when using the appropriate model (e.g., via the Responses API):\n",
        "\n",
        "* **WebSearchTool** ‚Äì Search the web for up-to-date information.\n",
        "* **FileSearchTool** ‚Äì Query your documents stored in OpenAI‚Äôs vector stores.\n",
        "* **ComputerTool** ‚Äì Let the agent control a remote computer (GUI interactions, browsing).\n",
        "* **CodeInterpreterTool** ‚Äì Run Python code in a secure sandbox.\n",
        "* **ImageGenerationTool** ‚Äì Generate images from text prompts.\n",
        "* **HostedMCPTool** ‚Äì Use tools exposed by remote MCP (Model Context Protocol) servers.\n",
        "* **LocalShellTool** ‚Äì Run shell commands on your local machine (rare but available).\n",
        "  ([OpenAI GitHub][1])\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "## **Why Use Hosted Tools?**\n",
        "\n",
        "* **Zero setup** ‚Äî no server, endpoint, or API to configure.\n",
        "* **Scalable and maintained** ‚Äî handled by OpenAI infra.\n",
        "* **Accessible** ‚Äî available in the SDK as simple Python class imports.\n",
        "* **Consistent experience** ‚Äî same tool behavior across agents/applications.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "## **How They Integrate in the Agent Loop**\n",
        "\n",
        "When using hosted tools:\n",
        "\n",
        "1. You declare them in your agent:\n",
        "\n",
        "   ```python\n",
        "   from agents import Agent, WebSearchTool, Runner\n",
        "\n",
        "   agent = Agent(\n",
        "       name=\"Research Assistant\",\n",
        "       instructions=\"Search and summarize web info.\",\n",
        "       tools=[WebSearchTool(), FileSearchTool(vector_store_ids=[\"DOCS\"])]\n",
        "   )\n",
        "   ```\n",
        "2. During runtime, if the LLM decides to use one:\n",
        "\n",
        "   * The SDK routes the tool call **automatically** to OpenAI's servers.\n",
        "   * Results come back and are merged into the loop as tool output.\n",
        "   * The agent continues reasoning seamlessly.\n",
        "     ([OpenAI GitHub][1], [DataCamp][2])\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "## **Quick Overview**\n",
        "\n",
        "| Hosted Tool          | Purpose                                       |\n",
        "| -------------------- | --------------------------------------------- |\n",
        "| WebSearchTool        | Internet search                               |\n",
        "| FileSearchTool       | Query your own vector-stored documents        |\n",
        "| ComputerTool         | Automate GUI/browser actions                  |\n",
        "| CodeInterpreterTool  | Execute Python code safely in a sandbox       |\n",
        "| ImageGenerationTool  | Generate images from text descriptions        |\n",
        "| HostedMCPTool        | Use tools exposed by remote MCP servers       |\n",
        "| LocalShellTool       | Run shell commands locally (use with caution) |\n",
        "| ([OpenAI GitHub][1]) |                                               |\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "### **TL;DR**\n",
        "\n",
        "* **Hosted tools** = ready-to-use, cloud-managed capabilities injected into agents.\n",
        "* They make your agents *capable*‚Äîallowing real actions like searching, coding, generating images, and more.\n",
        "* You just declare them; the SDK handles the rest.\n",
        "\n",
        "\n",
        "[1]: https://openai.github.io/openai-agents-python/tools/?utm_source=chatgpt.com \"Tools - OpenAI Agents SDK\"\n",
        "[2]: https://www.datacamp.com/tutorial/openai-agents-sdk-tutorial?utm_source=chatgpt.com \"OpenAI Agents SDK Tutorial: Building AI Systems That ...\"\n"
      ],
      "metadata": {
        "id": "LudoKnQZzznq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq openai-agents"
      ],
      "metadata": {
        "id": "WaTEWIFBvMXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "jSJb1sb0vQeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup vector store on OPENAI dsahboard\n",
        "\n",
        "1. Go to openai [Openai Platform][1]\n",
        "2. Go to dashbord ‚û° Logs ‚û° Vector Store\n",
        "3. Upload files\n",
        "4. Copy the Vector Id\n",
        "\n",
        "[1]: https://platform.openai.com/"
      ],
      "metadata": {
        "id": "lj1D-Pbbx6yC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "jb8qz7Gxvt1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, FileSearchTool, Runner, WebSearchTool\n",
        "\n",
        "agent = Agent(\n",
        "    name= \"Assistant\",\n",
        "    tools=[\n",
        "        WebSearchTool(),\n",
        "        FileSearchTool(\n",
        "            max_num_results= 3,\n",
        "            vector_store_ids=[\"vs_68b2eac12ad48191ad2ca50fa43388c5\"]\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "result = Runner.run_sync(agent, \"Show ayesha current orgaanization and jon title\")\n",
        "\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "id": "6um8Zr2ewMA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## check internet serch tool"
      ],
      "metadata": {
        "id": "48mCXCFNxzZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result =  Runner.run_sync(agent, \"Current Pakistan India News\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "id": "ilksWbepxupo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **RAG (Retrieval-Augmented Generation) System**\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "## 1. **Introduction**\n",
        "\n",
        "It‚Äôs like giving the AI a library card üìñ:\n",
        "\n",
        "* First, it retrieves real documents (from a knowledge base, database, or vector store).\n",
        "* Then, it augments the prompt (feeds docs + user query into the LLM).\n",
        "* Finally, the LLM generates an answer ‚Äî grounded in facts, not just memory.\n",
        "\n",
        "\n",
        "üëâ So the AI doesn‚Äôt ‚Äúguess‚Äù ‚Äî it ‚Äúlooks it up‚Äù before answering.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "## 2. **RAG Workflow**\n",
        "\n",
        "```\n",
        " User Question\n",
        "       ‚Üì\n",
        "   Retriever ‚Üí Fetches relevant documents from knowledge base\n",
        "       ‚Üì\n",
        "   Generator (LLM) ‚Üí Combines user query + docs\n",
        "       ‚Üì\n",
        " Final Answer (fact-based, accurate)\n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "## 3. **Components of RAG**\n",
        "\n",
        "1. **Knowledge Base**\n",
        "\n",
        "   * Stores external information (documents, PDFs, databases, websites).\n",
        "   * Usually stored in a **Vector Database** (FAISS, Pinecone, Weaviate).\n",
        "\n",
        "2. **Retriever**\n",
        "\n",
        "   * Converts both **documents** and **user queries** into **embeddings** (mathematical vectors).\n",
        "   * Finds the **most similar docs** using similarity search.\n",
        "\n",
        "3. **Generator (LLM)**\n",
        "\n",
        "   * Large Language Model (e.g., GPT-4.1).\n",
        "   * Takes retrieved docs + user query.\n",
        "   * Generates a **natural, fluent, fact-grounded answer**.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. **Example (Refund Policy Question)**\n",
        "\n",
        "* User asks: ‚ÄúWhat is the refund policy?‚Äù\n",
        "* Retriever searches company docs ‚Üí finds: *‚ÄúRefunds available within 30 days of purchase.‚Äù*\n",
        "* Generator forms response:\n",
        "\n",
        "  > ‚ÄúAccording to company policy, refunds can be requested within 30 days of purchase.‚Äù\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## 5. **Advantages of RAG**\n",
        "\n",
        "* ‚úÖ **Accuracy**: Reduces hallucinations by grounding answers in facts.\n",
        "* ‚úÖ **Freshness**: Uses the latest data without retraining the LLM.\n",
        "* ‚úÖ **Customization**: Can include private/company documents.\n",
        "* ‚úÖ **Efficiency**: Faster and cheaper than retraining models.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## 6. **Applications**\n",
        "\n",
        "* Chatbots with company knowledge (HR, IT support).\n",
        "* Legal assistants retrieving case laws.\n",
        "* Healthcare systems using medical research papers.\n",
        "* Search engines with natural language answers.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## 7. **Key Points (Cheat Sheet)**\n",
        "\n",
        "* RAG = **Retrieval + Generation**.\n",
        "* **Retriever** = fetch relevant info.\n",
        "* **Generator** = LLM answers using info.\n",
        "* **Knowledge Base** = external data (docs, DBs).\n",
        "* **Benefits** = accuracy, freshness, customization, reliability.\n",
        "\n",
        "---\n",
        "\n",
        "## **Summary**:\n",
        "RAG makes AI smarter by letting it **look up facts first (retrieval)** and then **answer naturally (generation)**.\n",
        "It is widely used to build **knowledge-grounded, domain-specific AI systems**.\n",
        "\n"
      ],
      "metadata": {
        "id": "m6HzJt4XJaeC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Vector Store**\n",
        "---\n",
        "## 1. **Introduction**\n",
        "\n",
        "* A **Vector Store** is a **special type of database** that stores and manages **embeddings** (numerical vector representations of text, images, etc.).\n",
        "* Used in AI systems for **semantic search** (finding meaning, not just keywords).\n",
        "\n",
        "üëâ Think of it as a **Google for meanings** rather than exact words.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## 2. **What Are Embeddings?**\n",
        "\n",
        "* **Embeddings** = numerical vectors that represent the meaning of data.\n",
        "* Example:\n",
        "\n",
        "  * ‚ÄúCar‚Äù ‚Üí \\[0.12, 0.87, -0.33, ‚Ä¶]\n",
        "  * ‚ÄúAutomobile‚Äù ‚Üí \\[0.11, 0.85, -0.35, ‚Ä¶]\n",
        "    ‚Üí Their vectors are **close together** because they mean the same thing.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## 3. **How a Vector Store Works**\n",
        "\n",
        "1. **Store Data as Vectors**\n",
        "\n",
        "   * Each document, sentence, or image ‚Üí converted into embeddings.\n",
        "   * Stored in the vector database.\n",
        "\n",
        "2. **Query Processing**\n",
        "\n",
        "   * User question also converted into an embedding.\n",
        "\n",
        "3. **Similarity Search**\n",
        "\n",
        "   * Vector store compares query embedding with stored embeddings.\n",
        "   * Returns the **closest matches** (most semantically relevant).\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## 6. **Popular Vector Stores**\n",
        "\n",
        "* **FAISS** (Facebook AI Similarity Search) ‚Üí open-source.\n",
        "* **Pinecone** ‚Üí cloud-based, scalable.\n",
        "* **Weaviate** ‚Üí advanced, open-source.\n",
        "* **Milvus** ‚Üí distributed vector DB.\n",
        "* **Chroma** ‚Üí popular in AI projects with LangChain.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## 7. **Advantages of Vector Stores**\n",
        "\n",
        "* ‚úÖ **Semantic search** (finds meaning, not just keywords).\n",
        "* ‚úÖ **Scalable** (handles millions of documents).\n",
        "* ‚úÖ **Efficient** (fast similarity search).\n",
        "* ‚úÖ **Essential for RAG** (retrieves context for LLMs).\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## **Summary**:\n",
        "A **Vector Store** is like a **semantic memory** for AI.\n",
        "It stores embeddings and lets systems **find relevant information based on meaning**, which is crucial for **RAG systems, chatbots, and search engines**.\n"
      ],
      "metadata": {
        "id": "zOE4EJyuMKne"
      }
    }
  ]
}