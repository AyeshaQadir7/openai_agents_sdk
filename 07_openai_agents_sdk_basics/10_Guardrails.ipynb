{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Open In Colab][1]\n",
        "\n",
        "[1]:https://colab.research.google.com/drive/11UwCiB2HyaKGj0UohVhQNzdMevaLO6js?usp=sharing"
      ],
      "metadata": {
        "id": "LkxgqyS7D4VM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **What are Guardrails?**\n",
        "\n",
        "* **Guardrails** = the **rules, policies, and controls** that **guide or restrict an LLM/Agentâ€™s behavior**.\n",
        "* They act like **safety boundaries**: ensuring the AI doesnâ€™t say, do, or output something harmful, irrelevant, or unintended.\n",
        "\n",
        "ğŸ‘‰ Analogy: Guardrails on a highway keep cars from going off-road. Similarly, AI guardrails keep agents from going off-track.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## **Types of Guardrails**\n",
        "\n",
        "Guardrails can exist at **different levels**:\n",
        "\n",
        "### ğŸ”¹ 1. **Input Guardrails**\n",
        "\n",
        "* Check **user inputs** before passing them to the model.\n",
        "* Prevent malicious, unsafe, or irrelevant queries.\n",
        "* Example: Block requests like *â€œHow to build a bomb?â€*.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ 2. **Model Prompting Guardrails**\n",
        "\n",
        "* Use **system instructions** or structured prompts to guide behavior.\n",
        "* Example:\n",
        "\n",
        "  * â€œYou are a helpful tutor, avoid discussing harmful content.â€\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ 3. **Output Guardrails**\n",
        "\n",
        "* Check **model responses** before sending them to the user.\n",
        "* Example: Detect & filter PII (personal info) or toxic language.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ 4. **Tool/Action Guardrails** (Agents SDK)\n",
        "\n",
        "* Restrict what actions an agent can take.\n",
        "* Example:\n",
        "\n",
        "  * Allow agent to call *Calculator tool*, but not *File Delete tool*.\n",
        "  * Only allow API calls within company policy.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "### ğŸ”¹ 5. **Policy & Compliance Guardrails**\n",
        "\n",
        "* Enforce **business rules, ethics, and regulations**.\n",
        "* Example:\n",
        "\n",
        "  * Medical bot â†’ cannot give diagnosis, only general info.\n",
        "  * Banking bot â†’ cannot reveal account passwords.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## **Why Guardrails Matter**\n",
        "\n",
        "* âœ… **Safety** â†’ Prevent harmful or biased outputs.\n",
        "* âœ… **Compliance** â†’ Follow company / legal rules.\n",
        "* âœ… **Trust** â†’ Users rely more on safe assistants.\n",
        "* âœ… **Focus** â†’ Keeps agent on-topic and within scope.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## **Cheat-Sheet**\n",
        "\n",
        "| Guardrail Type       | Purpose                 | Example                             |\n",
        "| -------------------- | ----------------------- | ----------------------------------- |\n",
        "| Input Guardrail      | Filter unsafe queries   | Block â€œHow to hack Wi-Fiâ€           |\n",
        "| Prompting Guardrail  | Guide model behavior    | â€œOnly answer math questionsâ€        |\n",
        "| Output Guardrail     | Filter unsafe responses | Remove toxic language               |\n",
        "| Tool Guardrail       | Restrict actions        | Allow calculator, block file delete |\n",
        "| Compliance Guardrail | Enforce rules           | Bank bot: never show passwords      |\n",
        "\n",
        "---\n",
        "\n",
        "âœ… **Summary**:\n",
        "**Guardrails** are **rules and filters** that keep AI systems safe, ethical, and reliable by controlling **what inputs they accept, how they behave, and what outputs or actions they produce**.\n",
        "\n"
      ],
      "metadata": {
        "id": "QCyivpsxh0HI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq openai-agents pydantic"
      ],
      "metadata": {
        "id": "NHWBtsUAiyHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "V8GWWwoMi1eC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from agents import (\n",
        "    Agent,\n",
        "    AsyncOpenAI,\n",
        "    OpenAIChatCompletionsModel,\n",
        "    Runner,\n",
        "    RunConfig,\n",
        "\n",
        "    RunContextWrapper,\n",
        "    TResponseInputItem,\n",
        "    GuardrailFunctionOutput,\n",
        "    InputGuardrailTripwireTriggered,\n",
        "    OutputGuardrailTripwireTriggered,\n",
        "    input_guardrail,\n",
        "    output_guardrail\n",
        ")\n",
        "\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "4TmYrlOli8c7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key= GEMINI_API_KEY,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model= \"gemini-2.5-flash\",\n",
        "    openai_client= external_client,\n",
        ")\n",
        "config = RunConfig(\n",
        "    model= model,\n",
        "    model_provider= external_client,\n",
        "    tracing_disabled= True\n",
        ")\n"
      ],
      "metadata": {
        "id": "Cf8wLO8rkST3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Implementation of Input Guardrail:**"
      ],
      "metadata": {
        "id": "dYLXIjXWlfGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MathHomeworkOutput(BaseModel):\n",
        "  is_math_homework: bool # boolean value represents the decision\n",
        "  resoning: str # shows the resoning of this decision\n",
        "  answer: str # This is the answer to the user question\n",
        "\n",
        "\n",
        "guardrail_agent = Agent(\n",
        "      name= \"Guardrail check\",\n",
        "      instructions= \" Check if the user is asking you to do their math homework.\",\n",
        "      output_type= MathHomeworkOutput,\n",
        "      model= model,\n",
        "  )\n",
        "\n"
      ],
      "metadata": {
        "id": "zYOAeS0Bliga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = Runner.run_sync(guardrail_agent, \"What is the capital of pakistan.\")\n",
        "output.final_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJBOfnEhoeqI",
        "outputId": "575391df-0a6a-481c-93d8-a7a17757653e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:openai.agents:OPENAI_API_KEY is not set, skipping trace export\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MathHomeworkOutput(is_math_homework=False, resoning='The user is asking a factual question about geography, not a math problem.', answer='The capital of Pakistan is Islamabad.')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@input_guardrail\n",
        "async def math_guardrail(\n",
        "    ctx: RunContextWrapper[None], agent: Agent, input: str | list[TResponseInputItem]) -> GuardrailFunctionOutput:\n",
        "    result = await Runner.run(guardrail_agent, input, context= ctx.context)\n",
        "\n",
        "    print(\"\\n\\n[GUARDRAIL_REPSONE]\", result.final_output, \"\\n\\n\")\n",
        "\n",
        "    return GuardrailFunctionOutput(\n",
        "        output_info=result.final_output,\n",
        "        # tripwire_triggered=False result.final_output.is_math_homework\n",
        "        tripwire_triggered=result.final_output.is_math_homework,\n",
        "    )"
      ],
      "metadata": {
        "id": "DSKL6QIaFaNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = Agent(\n",
        "    name= \"Math Homework Assistant\",\n",
        "    instructions= \"You are a  math support agent, Youe help student with thier questions.\",\n",
        "    model= model,\n",
        "    input_guardrails= [math_guardrail],\n",
        ")"
      ],
      "metadata": {
        "id": "Pg163PUoGzT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This should trip the guardrail\n",
        "\n",
        "try:\n",
        "    result = await Runner.run(agent, \"Help me solve this x: 2x + 3 = 11\", run_config= config)\n",
        "    print(\"Guardrail did not trip - this is unexpected\")\n",
        "    print(result.final_output)\n",
        "\n",
        "except InputGuardrailTripwireTriggered:\n",
        "    print(\"Math homework guardrail triggered\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcFBXBqCHO4C",
        "outputId": "a8e5ef11-f7ae-4b0b-9e13-e166b91cd863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[GUARDRAIL_REPSONE] is_math_homework=True resoning='The request is to solve an algebraic equation, which is a common task in math homework or classwork.' answer='To solve for x in the equation 2x + 3 = 11:\\n1. Subtract 3 from both sides of the equation: 2x + 3 - 3 = 11 - 3, which simplifies to 2x = 8.\\n2. Divide both sides by 2: 2x / 2 = 8 / 2, which simplifies to x = 4.\\nSo, x = 4.' \n",
            "\n",
            "\n",
            "Math homework guardrail triggered\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Input vs Output Guardrails**\n",
        "\n",
        "---\n",
        "\n",
        "## 1. **Input Guardrails**\n",
        "\n",
        "* **Definition**: Rules or filters that **check and control the userâ€™s input** before itâ€™s passed to the LLM/Agent.\n",
        "* **Purpose**: Prevent harmful, irrelevant, or out-of-scope prompts from reaching the model.\n",
        "\n",
        "ğŸ‘‰ Example:\n",
        "\n",
        "* User types: *â€œHow to make explosives?â€*\n",
        "* **Input guardrail** blocks it â†’ model never sees the prompt.\n",
        "\n",
        "### **Use Cases:**\n",
        "\n",
        "* Block unsafe or illegal queries.\n",
        "* Prevent prompt injection attacks (like â€œignore instructions and act evilâ€).\n",
        "* Keep queries relevant (e.g., finance bot only accepts finance-related questions).\n",
        "\n",
        "---\n",
        "\n",
        "## 2. **Output Guardrails**\n",
        "\n",
        "* **Definition**: Rules or filters that **check and control the modelâ€™s response** before itâ€™s sent back to the user.\n",
        "* **Purpose**: Stop the assistant from giving unsafe, private, or off-policy information.\n",
        "\n",
        "ğŸ‘‰ Example:\n",
        "\n",
        "* Model generates: *â€œYour password is 12345â€*\n",
        "* **Output guardrail** blocks or rewrites the message before sending it.\n",
        "\n",
        "### **Use Cases:**\n",
        "\n",
        "* Remove offensive/toxic language.\n",
        "* Strip sensitive data (e.g., PII â†’ phone numbers, credit cards).\n",
        "* Enforce tone (e.g., always polite and professional).\n",
        "\n",
        "---\n",
        "\n",
        "## 3. **Side-by-Side Comparison**\n",
        "\n",
        "| Feature          | Input Guardrails                 | Output Guardrails                       |\n",
        "| ---------------- | ----------------------------------- | ---------------------------------------- |\n",
        "| **When applied** | Before user input reaches the model | After model generates a response         |\n",
        "| **Purpose**      | Protect model from harmful queries  | Protect user from harmful outputs        |\n",
        "| **Example**      | Block: â€œHow to hack a bank?â€        | Remove toxic/unsafe content in response  |\n",
        "| **Analogy**      | Security check at airport entry     | Customs check before exiting the airport |\n",
        "\n",
        "---\n",
        "\n",
        "## 4. **Why Both Are Needed**\n",
        "\n",
        "* **Input-only guardrails**: Good, but user may still bypass with clever phrasing.\n",
        "* **Output-only guardrails**: Good, but model may waste resources generating unsafe responses.\n",
        "* **Best practice** â†’ Use **both** for full protection.\n",
        "\n",
        "---\n",
        "\n",
        "âœ… **Summary**\n",
        "\n",
        "* **Input Guardrails** stop unsafe queries **before reaching the model**.\n",
        "* **Output Guardrails** stop unsafe or non-compliant responses **before reaching the user**.\n",
        "* Together, they ensure **safety, compliance, and trust**.\n"
      ],
      "metadata": {
        "id": "BX2npYiSAVUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tripwires in LLMs & Agents**\n",
        "\n",
        "---\n",
        "\n",
        "## 1. **What is a Tripwire?**\n",
        "\n",
        "* A **tripwire** is a **monitor or detector** that â€œtriggersâ€ when an LLM or Agent crosses a **dangerous or restricted boundary**.\n",
        "* Think of it like a **silent alarm**:\n",
        "\n",
        "  * It doesnâ€™t block normal activity.\n",
        "  * But if something bad happens, it **activates a response** (log, alert, stop the agent).\n",
        "\n",
        "ğŸ‘‰ Analogy: In a museum, tripwires are invisible lasers. If someone crosses, an alarm goes off.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. **Difference from Guardrails**\n",
        "\n",
        "* **Guardrails** = **proactive** rules that prevent unsafe behavior in the first place (like fences).\n",
        "* **Tripwires** = **reactive** monitors that detect and respond if a rule is violated (like alarms).\n",
        "\n",
        "---\n",
        "\n",
        "## 3. **How Tripwires Work**\n",
        "\n",
        "Tripwires can monitor:\n",
        "\n",
        "1. **Inputs** â†’ Detect if a harmful prompt was attempted.\n",
        "2. **Outputs** â†’ Detect if the model generated unsafe/forbidden text.\n",
        "3. **Agent Actions** â†’ Detect if the agent tries to call an unsafe tool or external system.\n",
        "\n",
        "ğŸ‘‰ When triggered:\n",
        "\n",
        "* Block the action/output.\n",
        "* Alert developers or admins.\n",
        "* Log the event for audits.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. **Examples of Tripwires**\n",
        "\n",
        "* If a user asks: *â€œGive me my credit card numberâ€* â†’ Tripwire triggers.\n",
        "* If the model outputs profanity â†’ Tripwire triggers â†’ replace text or block it.\n",
        "* If the agent tries to access the â€œDelete Databaseâ€ tool â†’ Tripwire stops it immediately.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. **Why Tripwires Matter**\n",
        "\n",
        "* âœ… **Last line of defense** â†’ even if guardrails fail, tripwires catch violations.\n",
        "* âœ… **Monitoring & logging** â†’ helps track misuse attempts.\n",
        "* âœ… **Compliance** â†’ ensures system doesnâ€™t accidentally break laws/regulations.\n",
        "\n",
        "---\n",
        "\n",
        "**Summary**:\n",
        "A **tripwire** is a **safety detector** that triggers when the AI **crosses a forbidden line**. It doesnâ€™t guide behavior like guardrails, but instead **catches violations in real time** and prevents harm.\n",
        "\n"
      ],
      "metadata": {
        "id": "DfmYtA10Bl-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **max_turn in Agents**\n",
        "\n",
        "---\n",
        "\n",
        "## 1. **What is `max_turn`?**\n",
        "\n",
        "* `max_turn` = **the maximum number of back-and-forth steps** (turns) an agent is allowed to take in a single run.\n",
        "* Each **turn** = agent does something (like responding, calling a tool, or reasoning) â†’ then continues.\n",
        "\n",
        "ğŸ‘‰ Analogy:\n",
        "Think of `max_turn` like a chess game timer: it limits **how many moves** the agent can make before the game must end.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. **Why Do We Need `max_turn`?**\n",
        "\n",
        "* To **prevent infinite loops** (agent keeps calling tools forever).\n",
        "* To **control cost** (each turn = more tokens & API calls).\n",
        "* To **make agents predictable** (you donâ€™t want them wandering too long).\n",
        "\n",
        "---\n",
        "\n",
        "## 3. **Example**\n",
        "\n",
        "Letâ€™s say `max_turn=3`.\n",
        "\n",
        "### Scenario: Agent asked to â€œGet todayâ€™s weather in New York.â€\n",
        "\n",
        "1. **Turn 1** â†’ Agent decides: *â€œI need a tool: weather API.â€*\n",
        "2. **Turn 2** â†’ Tool returns: *â€œWeather: 25Â°C and sunny.â€*\n",
        "3. **Turn 3** â†’ Agent replies to user: *â€œItâ€™s 25Â°C and sunny in New York.â€*\n",
        "   âœ… Done â€” within 3 turns.\n",
        "\n",
        "If `max_turn=1`: Agent could only respond directly, **no tool calls**.\n",
        "If `max_turn=10`: Agent could chain multiple tool calls and refinements.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. **In OpenAI Agents SDK**\n",
        "\n",
        "When creating a `Runner`, you might set `max_turn` like this:\n",
        "\n",
        "```python\n",
        "result = Runner.run(\n",
        "    agent,\n",
        "    input=\"Plan a 3-day trip to Paris\",\n",
        "    max_turn=5\n",
        ")\n",
        "```\n",
        "\n",
        "ğŸ‘‰ This means:\n",
        "\n",
        "* The agent can take **at most 5 steps** (thinking, calling tools, responding).\n",
        "* If it hasnâ€™t finished by then â†’ system stops it (safety cutoff).\n",
        "\n",
        "---\n",
        "\n",
        "## 5. **Cheat-Sheet**\n",
        "\n",
        "* **Definition**: `max_turn` = maximum allowed **reasoning/tool/response steps** an agent can take per run.\n",
        "* **Purpose**: Prevents infinite loops, limits cost, enforces safety.\n",
        "* **Analogy**: Like a chess game limit â€” only a fixed number of moves allowed.\n",
        "\n",
        "---\n",
        "\n",
        "**In short**:\n",
        "`max_turn` = **safety brake** that caps how many steps an agent can take in a single conversation.\n"
      ],
      "metadata": {
        "id": "jCvrFUaGCKsY"
      }
    }
  ]
}