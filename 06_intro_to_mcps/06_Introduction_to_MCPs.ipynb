{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Why to Adopt OpenAI Agents SDK | Introduction to MCPs**"
      ],
      "metadata": {
        "id": "rFXA2hRBi15V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color= orange> **Why adopt the OpenAI Agents SDK?**</font>\n",
        "\n",
        "\n",
        "Because it lets you build **real, production-grade agentic apps** fast—using a **small set of primitives** (agents + tools + handoffs), **first-class tool use** (web/file/computer), **strong output contracts** (Structured Outputs), and **baked-in safety & observability**. It’s the shortest path from “idea” → “agent that actually does work.” ([OpenAI Platform][1], [OpenAI GitHub Pages][2], [OpenAI][3])\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## **1) Minimal mental model, maximum power**\n",
        "\n",
        "The SDK is intentionally **lightweight**: you define an **Agent** (instructions + model), give it **Tools** it can call, and optionally wire **Handoffs** (agent-to-agent). Fewer abstractions = easier to reason about and debug. ([OpenAI GitHub Pages][4])\n",
        "\n",
        "**Why it matters:** You spend time on your business logic, not framework plumbing.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## **2) First-class tool use (do real work, not just chat)**\n",
        "\n",
        "Out of the box you get **built-in tools** (web search, file search, computer use) and standard **function/tool calling** for your own APIs. Agents can call tools in **parallel** when needed. ([OpenAI][3], [OpenAI Platform][5])\n",
        "\n",
        "**Why it matters:** Your agent isn’t just talking; it’s acting—fetching data, reading files, clicking UIs, and calling your services.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## **3) Strong, reliable outputs (no more brittle regex hacks)**\n",
        "\n",
        "Use **Structured Outputs** (schema-validated JSON) so models must return exactly the shape you expect—way more reliable than ad-hoc parsing or plain JSON mode. ([OpenAI Platform][6])\n",
        "\n",
        "**Why it matters:** Safer integrations, fewer prod bugs, easier downstream processing.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## **4) Production features you’ll actually use**\n",
        "\n",
        "* **Streaming** for responsive UX\n",
        "* **Predicted outputs** to speed up known boilerplate parts of responses\n",
        "* **Multi-agent orchestration** via handoffs and “agents as tools”\n",
        "  All are supported directly in the platform & SDK. ([OpenAI Platform][7], [OpenAI GitHub Pages][2])\n",
        "\n",
        "**Why it matters:** Lower latency and cleaner architectures without bolt-ons.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## **5) Safety & guardrails built in**\n",
        "\n",
        "The SDK and OpenAI guides emphasize **guardrails**, safe tool use, and design patterns for predictable behavior—so you can ship with confidence. ([OpenAI GitHub Pages][8], [OpenAI CDN][9])\n",
        "\n",
        "**Why it matters:** Compliance and reliability aren’t afterthoughts.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## **6) Observability & debugging**\n",
        "\n",
        "There’s **tracing/telemetry** support referenced with the SDK so you can inspect agent runs, tool calls, and reasoning steps—critical for real ops. ([GitHub][10])\n",
        "\n",
        "**Why it matters:** You can see what the agent did when things go right (or wrong).\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## **7) Interoperability & future-proofing**\n",
        "\n",
        "* Works with OpenAI’s **Responses/Chat** APIs and is **provider-agnostic** per SDK repo notes.\n",
        "* Supports **remote MCP servers** for tool connectivity (a growing standard across agent ecosystems). ([GitHub][10], [OpenAI Platform][5])\n",
        "\n",
        "**Why it matters:** You aren’t boxed into one tooling island; your agents can reach many systems.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## **8) Batteries-included patterns and guides**\n",
        "\n",
        "OpenAI’s official docs give **clear recipes** (Agents overview, SDK guide, voice agents, tools) so you’re not starting from scratch each time. ([OpenAI Platform][11])\n",
        "\n",
        "**Why it matters:** Faster onboarding for teams—especially “new to agents” devs.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## **9) Clear evolution path**\n",
        "\n",
        "OpenAI is actively shipping **agent-native features** (e.g., web/file/computer tools; computer-using agents; ChatGPT agent UX patterns). Building on the SDK aligns you with that trajectory. ([OpenAI][3])\n",
        "\n",
        "**Why it matters:** Your stack stays current as agent capabilities expand.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "## **Concrete benefits by team role**\n",
        "\n",
        "* **PMs**: faster time-to-value with patterns that mirror how users *actually* interact with agents (multi-step, tool-using). ([OpenAI Platform][11])\n",
        "* **Engineers**: fewer abstractions, strong schemas, first-class tools, streaming. ([OpenAI Platform][1])\n",
        "* **Ops**: tracing + safer designs; easier incident triage. ([GitHub][10], [OpenAI CDN][9])\n",
        "\n",
        "\n",
        "\n",
        "[1]: https://platform.openai.com/docs/guides/agents-sdk?utm_source=chatgpt.com \"OpenAI Agents SDK\"\n",
        "[2]: https://openai.github.io/openai-agents-python/tools/?utm_source=chatgpt.com \"Tools - OpenAI Agents SDK\"\n",
        "[3]: https://openai.com/index/new-tools-for-building-agents/?utm_source=chatgpt.com \"New tools for building agents\"\n",
        "[4]: https://openai.github.io/openai-agents-python/?utm_source=chatgpt.com \"OpenAI Agents SDK\"\n",
        "[5]: https://platform.openai.com/docs/guides/tools?utm_source=chatgpt.com \"Using tools - OpenAI API\"\n",
        "[6]: https://platform.openai.com/docs/guides/structured-outputs?utm_source=chatgpt.com \"Structured model outputs - OpenAI API\"\n",
        "[7]: https://platform.openai.com/docs/guides/streaming-responses?utm_source=chatgpt.com \"Streaming API responses\"\n",
        "[8]: https://openai.github.io/openai-agents-python/ref/agent/?utm_source=chatgpt.com \"OpenAI Agents SDK\"\n",
        "[9]: https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf?utm_source=chatgpt.com \"A practical guide to building agents\"\n",
        "[10]: https://github.com/openai/openai-agents-python?utm_source=chatgpt.com \"openai/openai-agents-python: A lightweight, powerful ...\"\n",
        "[11]: https://platform.openai.com/docs/guides/agents?utm_source=chatgpt.com \"Agents - OpenAI API\"\n"
      ],
      "metadata": {
        "id": "-6m1Fg-JxMnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color= orange>**OpenAI Agents SDK vs. Others**</font>\n",
        "\n",
        "\n",
        "## 1. **Mental Model & Simplicity**\n",
        "\n",
        "* **Agents SDK** →\n",
        "\n",
        "  * Very small set of concepts: **Agent**, **Tool**, **Handoff**.\n",
        "  * Feels like “just add glue between LLM and tools.”\n",
        "  * Easy for *beginners* and *production engineers*.\n",
        "\n",
        "* **LangChain** →\n",
        "\n",
        "  * Huge ecosystem, many abstractions (chains, retrievers, memories, executors…).\n",
        "  * Powerful, but **steep learning curve**.\n",
        "  * Often overwhelming for simple use cases.\n",
        "\n",
        "* **CrewAI** →\n",
        "\n",
        "  * Designed around **teams of agents** with roles (CEO, researcher, writer).\n",
        "  * Good for *simulation / brainstorming*, but heavy if you just want one practical agent.\n",
        "\n",
        "* **AutoGen** →\n",
        "\n",
        "  * Conversation-first, agents “talk” to each other.\n",
        "  * Feels more like a **research playground** than a production SDK.\n",
        "\n",
        "**Winner (for simplicity): Agents SDK**\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## 2. **Tool Use (the “hands” of agents)**\n",
        "\n",
        "* **Agents SDK** →\n",
        "\n",
        "  * **Built-in tools**: web search, file search, computer-use.\n",
        "  * Tools can run **in parallel** (saves time).\n",
        "  * Easy to add **custom function tools**.\n",
        "\n",
        "* **LangChain** →\n",
        "\n",
        "  * Giant library of tools/connectors (databases, APIs, etc).\n",
        "  * But: tool invocation is sometimes **fragile** and less standardized.\n",
        "\n",
        "* **CrewAI** →\n",
        "\n",
        "  * Agents use “skills,” but mostly rely on role-play and conversation.\n",
        "  * Less focus on serious API/tool orchestration.\n",
        "\n",
        "* **AutoGen** →\n",
        "\n",
        "  * Tool calling supported, but not as **first-class**.\n",
        "  * More focused on agent-agent conversation than structured tool execution.\n",
        "\n",
        "**Winner (for practical tool use): Agents SDK**\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## 3. **Output Reliability**\n",
        "\n",
        "* **Agents SDK** →\n",
        "\n",
        "  * **Structured Outputs** (schema-validated JSON).\n",
        "  * No more fragile regex/json parsing.\n",
        "\n",
        "* **LangChain** →\n",
        "\n",
        "  * Has JSON output parsers, but less strict—models can still mess up.\n",
        "\n",
        "* **CrewAI** →\n",
        "\n",
        "  * Mostly unstructured natural language exchanges.\n",
        "  * Not designed for **production-grade outputs**.\n",
        "\n",
        "* **AutoGen** →\n",
        "\n",
        "  * Outputs are free-form chat messages unless you build custom parsers.\n",
        "\n",
        "**Winner (for reliability): Agents SDK**\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## 4. **Production Features**\n",
        "\n",
        "* **Agents SDK** →\n",
        "\n",
        "  * **Streaming** (fast responses).\n",
        "  * **Predicted outputs** (faster known parts).\n",
        "  * **Tracing/observability** (debugging what the agent did).\n",
        "  * Guardrails built in.\n",
        "\n",
        "* **LangChain** →\n",
        "\n",
        "  * Great experimentation sandbox.\n",
        "  * Production readiness requires lots of extra engineering (monitoring, observability).\n",
        "\n",
        "* **CrewAI** →\n",
        "\n",
        "  * Fun for experiments, **not really production-focused**.\n",
        "\n",
        "* **AutoGen** →\n",
        "\n",
        "  * Good for research demos.\n",
        "  * Production support is minimal—teams often migrate away when scaling.\n",
        "\n",
        "**Winner (for production): Agents SDK**\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## 5. **Community & Ecosystem**\n",
        "\n",
        "* **LangChain** →\n",
        "\n",
        "  * Massive open-source ecosystem, tons of integrations.\n",
        "  * Strong community, but codebase is complex.\n",
        "\n",
        "* **Agents SDK** →\n",
        "\n",
        "  * Smaller ecosystem (newer).\n",
        "  * Backed by OpenAI (fast updates, roadmap-aligned).\n",
        "\n",
        "* **CrewAI & AutoGen** →\n",
        "\n",
        "  * Smaller, niche communities.\n",
        "  * Good for experiments, but not “enterprise adoption” scale.\n",
        "\n",
        "**Winner (for integrations today): LangChain**\n",
        "\n",
        "**Winner (for future-proof, roadmap alignment): Agents SDK**\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## 6. **Use Case Fit**\n",
        "\n",
        "* **Agents SDK** →\n",
        "\n",
        "  * Best for **production apps** that need real-world tool use, structured outputs, and reliability.\n",
        "\n",
        "* **LangChain** →\n",
        "\n",
        "  * Best for **exploration / research** and when you need **lots of connectors** (databases, APIs).\n",
        "\n",
        "* **CrewAI** →\n",
        "\n",
        "  * Best for **role-based, multi-agent collaboration experiments** (like AI “teams” simulating humans).\n",
        "\n",
        "* **AutoGen** →\n",
        "\n",
        "  * Best for **academic/research experiments** on agent-to-agent communication.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "# **Overall Verdict**\n",
        "\n",
        "👉 If your goal is to **ship a reliable, production-ready agent** that uses tools, APIs, and structured outputs → **OpenAI Agents SDK** is the best bet.\n",
        "\n",
        "👉 If you want **lots of integrations right now** and don’t mind complexity → **LangChain** wins.\n",
        "\n",
        "👉 If you want to **play with multi-agent teamwork / simulations** → **CrewAI** or **AutoGen** are fun sandboxes.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "### **Analogy:**\n",
        "\n",
        "* **LangChain** = Giant Lego box with thousands of weird pieces (powerful but messy).\n",
        "* **CrewAI** = Pretend play game where each doll has a role (fun but limited).\n",
        "* **AutoGen** = AI research lab toy (good for experiments, not industry).\n",
        "* **Agents SDK** = Ikea toolkit → small set of tools, but they fit perfectly, and you can build real furniture fast.\n",
        "\n"
      ],
      "metadata": {
        "id": "VxvgyFg0E9GB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color= orange>**Short-term VS Long-term Agent Workflow**</font>\n",
        "\n",
        "* **Short-term agent workflow** → what happens *right now* when an agent is solving a single request.\n",
        "* **Long-term agent workflow** → how agents can handle tasks that span *hours, days, or even indefinitely*, using memory, planning, and persistence.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "# **Short-Term Agent Workflow (One-off Task)**\n",
        "\n",
        "Think of this as **“answer my question right now”**.\n",
        "Steps usually look like this:\n",
        "\n",
        "1. **User Request**\n",
        "\n",
        "   * You ask: “Summarize this PDF and email me the key points.”\n",
        "\n",
        "2. **Agent Receives Input**\n",
        "\n",
        "   * Agent reads the prompt and context.\n",
        "\n",
        "3. **Reasoning / Planning**\n",
        "\n",
        "   * Agent decides:\n",
        "\n",
        "     1. Get the PDF\n",
        "     2. Summarize contents\n",
        "     3. Format summary\n",
        "     4. Send email\n",
        "\n",
        "4. **Tool Use (Action Phase)**\n",
        "\n",
        "   * Agent uses tools in order:\n",
        "\n",
        "     * File tool → open PDF\n",
        "     * Summarization tool (LLM) → create summary\n",
        "     * Email API tool → send email\n",
        "\n",
        "5. **Return Response**\n",
        "\n",
        "   * Agent tells you:\n",
        "   > “Summary sent to your inbox.”\n",
        "\n",
        "⚡ This is **stateless** → once done, the agent forgets everything unless explicitly logged.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "# **Long-Term Agent Workflow (Persistent Task)**\n",
        "\n",
        "Now imagine **“be my ongoing assistant over days/weeks”**.\n",
        "The flow adds memory + persistence:\n",
        "\n",
        "1. **User Goal (Ongoing)**\n",
        "\n",
        "   * “Track all my project files, summarize weekly progress, and remind me of deadlines.”\n",
        "\n",
        "2. **Agent Receives Input + Context**\n",
        "\n",
        "   * Keeps **long-term memory** (vector database, structured notes, or file-based logs).\n",
        "\n",
        "3. **Planning (Across Time)**\n",
        "\n",
        "   * Builds a **schedule / task graph**:\n",
        "\n",
        "     * Daily → scan files\n",
        "     * Weekly → compile report\n",
        "     * Before deadlines → send reminders\n",
        "\n",
        "4. **Execution Over Time**\n",
        "\n",
        "   * Agent wakes up at intervals (cron jobs, triggers, events).\n",
        "   * Uses tools to gather new data, compare with memory, and update state.\n",
        "\n",
        "5. **Adaptation**\n",
        "\n",
        "   * If a new project file appears, agent updates its plan.\n",
        "   * If a deadline shifts, memory gets updated.\n",
        "\n",
        "6. **Feedback Loop**\n",
        "\n",
        "   * User corrections → stored in long-term memory.\n",
        "   * Agent refines future behavior.\n",
        "\n",
        "⚡ This is **stateful & persistent** → agent keeps learning and adjusting over time.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "# **Quick Comparison**\n",
        "\n",
        "| Aspect   | Short-Term Workflow      | Long-Term Workflow                      |\n",
        "| -------- | ------------------------ | --------------------------------------- |\n",
        "| Memory   | None (stateless)         | Persistent (DB, logs, embeddings)       |\n",
        "| Scope    | Single question/task     | Ongoing, multi-step, evolving           |\n",
        "| Tools    | Used once per request    | Reused + scheduled over time            |\n",
        "| Planning | Linear (do X, then Y)    | Adaptive (re-plan based on changes)     |\n",
        "| Example  | “Summarize this PDF now” | “Be my research assistant for 6 months” |\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "**Think of it like this:**\n",
        "\n",
        "* **Short-term agent** = “Uber driver” → one trip, done.\n",
        "* **Long-term agent** = “Personal chauffeur” → knows your schedule, adapts, and drives you daily."
      ],
      "metadata": {
        "id": "RGJrzTm4IoL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color= orange>**Introduction to MCPs**<font>"
      ],
      "metadata": {
        "id": "ee0HP1kU-zsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **What is MCP?**\n",
        "\n",
        "**MCP = Model Context Protocol**\n",
        "\n",
        "It’s a **new open standard** that lets AI models (like agents) connect to **external tools, data, and services** in a safe, consistent way.\n",
        "\n",
        "Think of MCP as a **universal translator** between:\n",
        "\n",
        "* 🧠 **LLM/Agent** → wants to use a tool (“search the web”, “fetch data from database”)\n",
        "* 🔧 **Tool/Service** → actual thing that does the work (API, DB, filesystem, app)\n",
        "\n",
        "MCP sits in the middle, making sure they can “talk” to each other.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "# **Why MCP Exists**\n",
        "\n",
        "Without MCP:\n",
        "\n",
        "* Each framework (LangChain, CrewAI, Agents SDK…) has its **own way** of defining tools.\n",
        "* This leads to **incompatibility** → a tool built for LangChain might not work in AutoGen.\n",
        "\n",
        "With MCP:\n",
        "\n",
        "* Tools are defined once and can work **everywhere**.\n",
        "* Like how **USB** lets any keyboard plug into any computer, MCP lets any tool plug into any agent framework.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "# **How MCP Works (Simple Flow)**\n",
        "\n",
        "1. **MCP Server** → where your tools live (APIs, database connectors, file system access).\n",
        "2. **MCP Client** → the agent or LLM that wants to use tools.\n",
        "3. **Protocol (JSON-based)** → defines how client ↔ server talk:\n",
        "\n",
        "   * List tools\n",
        "   * Call tools with structured inputs/outputs\n",
        "   * Return results\n",
        "\n",
        "Example:\n",
        "\n",
        "```\n",
        "Agent → MCP → Tool\n",
        "“Search for ‘AI news’” → WebSearch tool → returns headlines\n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "# **Why MCP Matters (Benefits)**\n",
        "\n",
        "* **Interoperability** → write a tool once, use it in any agent framework.\n",
        "* **Safety** → defines strict contracts so agents don’t misuse tools.\n",
        "* **Ecosystem Growth** → tool developers don’t need to rebuild for every SDK.\n",
        "* **Future-Proof** → OpenAI, Anthropic, and others are rallying around MCP.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "# **Analogy**\n",
        "\n",
        "Think of MCP like **“app stores” for AI agents**:\n",
        "\n",
        "* Before MCP → every phone had its own weird apps (Nokia apps didn’t run on iPhone).\n",
        "* After MCP → one standard (App Store/Play Store) → apps run everywhere.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "✅ In short:\n",
        "**MCP is a universal language that lets AI agents safely and consistently use external tools, no matter which framework you’re using.**\n",
        "\n"
      ],
      "metadata": {
        "id": "_QFm4Jn24R6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **What is a Function Schema?**\n",
        "\n",
        "A **function schema** is basically a **blueprint** that tells an LLM:\n",
        "\n",
        "* What the function (or tool) is called\n",
        "* What inputs it expects (parameters, their types, whether they are required)\n",
        "* What the function does (description)\n",
        "\n",
        "It’s like giving the model a **menu card** so it knows:\n",
        "👉 what tools are available\n",
        "👉 how to correctly “call” them\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "# **Why is it Needed?**\n",
        "\n",
        "* LLMs output text by default.\n",
        "* But for **tool calling**, the LLM must produce **structured data** (JSON).\n",
        "* Function schemas give the model strict instructions on:\n",
        "\n",
        "  * parameter names\n",
        "  * data types\n",
        "  * valid values\n",
        "\n",
        "This prevents hallucinations like:\n",
        "\n",
        "❌ `\"call_weather_api(city_namez='New Yark')\"`\n",
        "\n",
        "✅ `\"call_weather_api(city='New York')\"`\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "# **Example of a Function Schema (OpenAI-style)**\n",
        "\n",
        "```python\n",
        "{\n",
        "  \"name\": \"get_weather\",\n",
        "  \"description\": \"Get the current weather in a given city\",\n",
        "  \"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"city\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"The name of the city\"\n",
        "      },\n",
        "      \"unit\": {\n",
        "        \"type\": \"string\",\n",
        "        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
        "        \"description\": \"Unit for temperature\"\n",
        "      }\n",
        "    },\n",
        "    \"required\": [\"city\"]\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "### Breakdown:\n",
        "\n",
        "* **name** → what the function is called (`get_weather`)\n",
        "* **description** → what the function does\n",
        "* **parameters** → input details\n",
        "\n",
        "  * `city` is required\n",
        "  * `unit` is optional, but must be either `\"celsius\"` or `\"fahrenheit\"`\n",
        "\n",
        "So when the LLM decides to call this tool, it will output **structured JSON** like:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"name\": \"get_weather\",\n",
        "  \"arguments\": {\n",
        "    \"city\": \"London\",\n",
        "    \"unit\": \"celsius\"\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "# **Benefits of Function Schema**\n",
        "\n",
        "1. **Structure & Reliability**\n",
        "\n",
        "   * Ensures LLM calls tools with valid arguments\n",
        "   * Reduces “hallucinations” in tool usage\n",
        "\n",
        "2. **Discoverability**\n",
        "\n",
        "   * LLMs can “read” the schema to know what tools exist\n",
        "\n",
        "3. **Interoperability**\n",
        "\n",
        "   * Any LLM supporting function calling (OpenAI, Anthropic, etc.) can use the same schema\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "# **Analogy**\n",
        "\n",
        "Think of the LLM as a **chef**.\n",
        "\n",
        "* Without a recipe (schema), it just guesses what ingredients to use.\n",
        "* With a recipe (function schema), it knows exactly:\n",
        "\n",
        "  * what ingredients (parameters) are needed\n",
        "  * in what form (string, number, enum)\n",
        "  * to make the dish (function call) correctly.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "✅ **In short:**\n",
        "A **function schema** is the **structured recipe** that guides LLMs to call external tools/functions correctly and safely.\n",
        "\n"
      ],
      "metadata": {
        "id": "hYRV5MXVHdNg"
      }
    }
  ]
}